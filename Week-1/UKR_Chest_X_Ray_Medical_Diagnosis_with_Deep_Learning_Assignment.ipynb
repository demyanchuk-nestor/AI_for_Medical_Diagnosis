{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/demyanchuk-nestor/AI_for_Medical_Diagnosis/blob/master/Week-1/UKR_Chest_X_Ray_Medical_Diagnosis_with_Deep_Learning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLci7kagHqU0"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/demyanchuk-nestor/AI_for_Medical_Diagnosis\n",
    "%cd 'AI_for_Medical_Diagnosis/Week-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd9mDcWibwLC"
   },
   "source": [
    "# Chest X-Ray Medical Diagnosis with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZYK-0rin5x7"
   },
   "source": [
    "<img src=\"https://github.com/hardik0/AI-for-Medicine-Specialization/blob/master/AI-for-Medical-Diagnosis/Week-1/xray-header-image.png?raw=true\" style=\"padding-top: 50px;width: 87%;left: 0px;margin-left: 0px;margin-right: 0px;\">\n",
    "** Завдання 7, 8!**\n",
    "\n",
    "У цьому завданні! Ви вивчите діагностику медичних зображень шляхом створення сучасного класифікатора рентгенівських знімків грудної клітки за допомогою Keras.\n",
    "\n",
    "У завданні будуть розглянуті деякі етапи побудови та оцінки цієї моделі класифікатора з глибоким навчанням. Зокрема, ви повинні будете\n",
    "- Попередньо обробити та підготувати реальний набір рентгенівських знімків\n",
    "- Використовувати навчання з перенавчанням для перенавчання моделі DenseNet для класифікації рентгенівських зображень\n",
    "- Вивчите техніку обробки дисбалансу класів\n",
    "- Вимірювання діагностичної ефективності шляхом обчислення AUC (площа під кривою) для кривої ROC (робоча характеристика приймача)\n",
    "- Візуалізувати активність моделі за допомогою GradCAM\n",
    "\n",
    "Виконуючи це завдання, ви дізнаєтесь про наступні теми:\n",
    "\n",
    "- Підготовка даних\n",
    "  - Візуалізація даних\n",
    "  - Запобігання витоку даних\n",
    "- Розробка моделі\n",
    "  - Усунення дисбалансу класів\n",
    "  - Використання попередньо навчених моделей з використанням навчання з переносом\n",
    "- Оцінювання\n",
    "  - Криві AUC та ROC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n2Ai8_AbwLQ"
   },
   "source": [
    "\n",
    "\n",
    "Використовуйте ці посилання, щоб переходити до певних розділів цього завдання!\n",
    "\n",
    "- [1. Імпорт даних і функцій](#1)\n",
    "- [2. Завантажте набори даних](#2)\n",
    "- [3. Розробка моделі](#3)\n",
    "- [4. Навчання [необов’язково]](#4)\n",
    "\n",
    "- [5. Прогнозування та оцінка](#5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XI8PBrk_2Z4V"
   },
   "source": [
    "<a name='1'></a>\n",
    "##  1. Дані та функції для імпорту¶\n",
    "\n",
    "Ми скористаємося наступними даними:\n",
    "- `*numpy*` та `*pandas*` для маніпулювання даними\n",
    "- `*matplotlib.pyplot*` та `*seaborn*` для створення графіків для візуалізації\n",
    "- `*util*` надасть локально визначені утиліти, які були надані для цього завдання\n",
    "\n",
    "\n",
    "\n",
    "Запустіть наступну комірку, щоб імпортувати всі необхідні пакунки.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lB7qT-Nrk85Y"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.24.3\n",
    "!pip install pandas==1.5.2\n",
    "!pip install tensorflow==2.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Je3yV0Wnn5x8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "# import tensorflow.python.keras.backend as K\n",
    "import tensorflow.python.keras.backend as K\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import util\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PMDCWQRn5yA"
   },
   "source": [
    "<a name='2'></a>\n",
    "\n",
    "**2 Завантаження наборів даних**\n",
    "\n",
    "Для цього завдання ми будемо використовувати набір даних ChestX-ray8, який містить 108 948 рентгенівських знімків у прямій проекції 32 717 унікальних пацієнтів.\n",
    "\n",
    "Кожне зображення в наборі даних містить кілька текстових міток, що ідентифікують 14 різних патологічних станів.\n",
    "Вони, в свою чергу, можуть бути використані лікарями для діагностики 8 різних захворювань.\n",
    "Ми використаємо ці дані для розробки єдиної моделі, яка надасть бінарні класифікаційні прогнози для кожної з 14 позначених патологій.\n",
    "Іншими словами, вона передбачатиме «позитивний» або «негативний» результат для кожної з патологій.\n",
    "Ви можете безкоштовно завантажити весь набір даних тут.\n",
    "\n",
    "\n",
    "Щоб полегшити вам роботу, ми обробили мітки для нашої невеликої вибірки і згенерували три нові файли, з яких ви можете почати. Ось ці файли:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwMFv7InbwMm"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RlvKgFB1bwMz"
   },
   "source": [
    "\n",
    " Прочитайте дані\n",
    "Відкриємо ці файли за допомогою бібліотеки [pandas](https://pandas.pydata.org/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5JRSHB7i0t_6"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../nih/train-small.csv\")\n",
    "valid_df = pd.read_csv(\"../nih/valid-small.csv\")\n",
    "test_df = pd.read_csv(\"../nih/test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mrDoMlsun5yE"
   },
   "outputs": [],
   "source": [
    "labels = ['Cardiomegaly',\n",
    "          'Emphysema',\n",
    "          'Effusion',\n",
    "          'Hernia',\n",
    "          'Infiltration',\n",
    "          'Mass',\n",
    "          'Nodule',\n",
    "          'Atelectasis',\n",
    "          'Pneumothorax',\n",
    "          'Pleural_Thickening',\n",
    "          'Pneumonia',\n",
    "          'Fibrosis',\n",
    "          'Edema',\n",
    "          'Consolidation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mHwweJrk85b"
   },
   "source": [
    "\n",
    "Візуалізація зображень за класами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-0CDw-6k85c"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Atelectasis\"\n",
    "train_class = train_df.loc[train_df['Atelectasis']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Atelectasis\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JtscYwMk85c"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Cardiomegaly\"\n",
    "train_class = train_df.loc[train_df['Cardiomegaly']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Cardiomegaly\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tR4z5PCTk85c"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Consolidation\"\n",
    "train_class = train_df.loc[train_df['Consolidation']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Consolidation\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TM_x-7Bwk85c"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Edema\"\n",
    "train_class = train_df.loc[train_df['Edema']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Edema\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-iLH3Bbk85d"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Effusion\"\n",
    "train_class = train_df.loc[train_df['Effusion']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Effusion\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4GRBsJrk85d"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Emphysema\"\n",
    "train_class = train_df.loc[train_df['Emphysema']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Emphysema\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IF3e4WT8k85d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Fibrosis\"\n",
    "train_class = train_df.loc[train_df['Fibrosis']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Fibrosis\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dN7WKYrRk85d"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Hernia\"\n",
    "train_class = train_df.loc[train_df['Hernia']==1,:]\n",
    "\n",
    "number_of_images = 2\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Hernia\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCCArT45k85e"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Infiltration\"\n",
    "train_class = train_df.loc[train_df['Infiltration']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Infiltration\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrhjSbeRk85e"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Mass\"\n",
    "train_class = train_df.loc[train_df['Mass']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Mass\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEa_Wzm0k85e"
   },
   "outputs": [],
   "source": [
    "# Visualize images for class \"Nodule\"\n",
    "train_class = train_df.loc[train_df['Nodule']==1,:]\n",
    "\n",
    "number_of_images = 9\n",
    "custom_df = train_class.sample(n=number_of_images)\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "\n",
    "fig.suptitle('Images with \"Nodule\" diagnosis', fontsize=16)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlN_t7ZubwT4"
   },
   "source": [
    "<a name='Ex-1'></a>\n",
    "**Вправа 1** - Перевірка витоку даних\n",
    "У комірці нижче напишіть функцію для перевірки наявності витоку між двома наборами даних. Ми використаємо її, щоб переконатися, що в тестовому наборі немає пацієнтів, які також присутні в тренувальному або перевірочному наборах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jz6dwTSrUcKc"
   },
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    \"\"\"\n",
    "    Return True if there any patients are in both df1 and df2.\n",
    "\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "\n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "    df1_patients_unique = set(df1[patient_col])\n",
    "    df2_patients_unique = set(df2[patient_col])\n",
    "\n",
    "    patients_in_both_groups = len(list(df1_patients_unique.intersection(df2_patients_unique)))\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = False if patients_in_both_groups == 0 else True # boolean (true if there is at least 1 patient in both groups)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rh2p1krrV1g5"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "print(\"test case 1\")\n",
    "df1 = pd.DataFrame({'patient_id': [0, 1, 2]})\n",
    "df2 = pd.DataFrame({'patient_id': [2, 3, 4]})\n",
    "print(\"df1\")\n",
    "print(df1)\n",
    "print(\"df2\")\n",
    "print(df2)\n",
    "print(f\"leakage output: {check_for_leakage(df1, df2, 'patient_id')}\")\n",
    "print(\"-------------------------------------\")\n",
    "print(\"test case 2\")\n",
    "df1 = pd.DataFrame({'patient_id': [0, 1, 2]})\n",
    "df2 = pd.DataFrame({'patient_id': [3, 4, 5]})\n",
    "print(\"df1:\")\n",
    "print(df1)\n",
    "print(\"df2:\")\n",
    "print(df2)\n",
    "\n",
    "print(f\"leakage output: {check_for_leakage(df1, df2, 'patient_id')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3K5lDehbwUv"
   },
   "source": [
    "##### Очікувані результати\n",
    "\n",
    "```Python\n",
    "test case 1\n",
    "df1\n",
    "   patient_id\n",
    "0           0\n",
    "1           1\n",
    "2           2\n",
    "df2\n",
    "   patient_id\n",
    "0           2\n",
    "1           3\n",
    "2           4\n",
    "leakage output: True\n",
    "-------------------------------------\n",
    "test case 2\n",
    "df1:\n",
    "   patient_id\n",
    "0           0\n",
    "1           1\n",
    "2           2\n",
    "df2:\n",
    "   patient_id\n",
    "0           3\n",
    "1           4\n",
    "2           5\n",
    "leakage output: False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCWkiLudW_Il"
   },
   "source": [
    "Перейдіть до наступної клітинки, щоб перевірити, чи є пацієнти в тренуванні та тестуванні, або в дійсності та тестуванні."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AMF3Wd3yW-RS"
   },
   "outputs": [],
   "source": [
    "print(\"leakage between train and test: {}\".format(check_for_leakage(train_df, test_df, 'PatientId')))\n",
    "print(\"leakage between valid and test: {}\".format(check_for_leakage(valid_df, test_df, 'PatientId')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRUvYHpYXhlQ"
   },
   "source": [
    "Якщо ми отримали `***False***` для обох, то ми готові почати підготовку наборів даних для навчання. Не забувайте завжди перевіряти на витік даних!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgvV74rg7FSN"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPjuZHPpn5yH"
   },
   "source": [
    "Для цього ми скористаємося готовим класом *ImageDataGenerator *з фреймворку *Keras*, який дозволяє створити «генератор» зображень, вказаних у фреймі даних.\n",
    "Цей клас також забезпечує підтримку базового доповнення даних, такого як випадкове горизонтальне перевертання зображень.\n",
    "Ми також використовуємо генератор для перетворення значень у кожній партії так, щоб їхнє середнє значення дорівнювало 0, а стандартне відхилення - 1.\n",
    "Це полегшить навчання моделі, стандартизувавши розподіл вхідних даних.\n",
    "Генератор також перетворює наші одноканальні рентгенівські зображення (у сірій шкалі) у триканальний формат, повторюючи значення на зображенні у всіх каналах.\n",
    "Нам це потрібно, оскільки попередньо навчена модель, яку ми будемо використовувати, вимагає триканальних входів.\n",
    "Оскільки це переважно питання читання і розуміння документації Keras, ми реалізували генератор для вас. Є кілька речей, на які слід звернути увагу:\n",
    "\n",
    "Ми нормалізуємо середнє та стандартне відхилення даних\n",
    "Ми перемішуємо вхідні дані після кожної епохи.\n",
    "Ми встановлюємо розмір зображення 320px на 320px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAgVGOAju8pX"
   },
   "outputs": [],
   "source": [
    "print(\"getting train generator...\")\n",
    "\n",
    "# Normalize images\n",
    "image_generator = ImageDataGenerator(\n",
    "    samplewise_center=True, #Set each sample mean to 0.\n",
    "    samplewise_std_normalization= True # Divide each input by its standard deviation\n",
    ")\n",
    "# Flow from directory with specified batch size and target image size\n",
    "train_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=\"../nih/images_small/\",\n",
    "        x_col=\"Image\", # features\n",
    "        y_col= labels, # labels\n",
    "        class_mode=\"raw\", # 'Mass' column should be in train_df\n",
    "        batch_size= 8, # images per batch\n",
    "        seed= 1,\n",
    "        shuffle=True, # shuffle the rows or not\n",
    "        target_size=(320,320) # width and height of output image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpRXR-3_u7cl"
   },
   "source": [
    "####\n",
    "Створіть окремий генератор для валідних і тестових наборів\n",
    "Тепер нам потрібно створити новий генератор для валідних і тестових даних.\n",
    "\n",
    "Чому ми не можемо використовувати той самий генератор, що і для навчальних даних?\n",
    "\n",
    "Подивіться на генератор, який ми написали для навчальних даних.\n",
    "\n",
    "Він нормалізує кожне зображення для кожної партії, тобто використовує пакетну статистику.\n",
    "Ми не повинні робити цього з тестовими та валідаційними даними, оскільки в реальному житті ми не обробляємо вхідні зображення пакетом за раз (ми обробляємо по одному зображенню за раз).\n",
    "Знання середнього значення за партію тестових даних фактично дасть нашій моделі перевагу.\n",
    "Модель не повинна мати жодної інформації про тестові дані.\n",
    "Що нам потрібно зробити, так це нормалізувати вхідні тестові дані, використовуючи статистику, обчислену на навчальній вибірці.\n",
    "\n",
    "Ми реалізуємо це у функції нижче.\n",
    "Є одне технічне зауваження. В ідеалі, ми хотіли б обчислити середнє значення вибірки і стандартне відхилення, використовуючи весь навчальний набір.\n",
    "Однак, оскільки він надзвичайно великий, це забрало б багато часу.\n",
    "Для економії часу ми візьмемо випадкову вибірку з набору даних і обчислимо вибіркове середнє і вибіркове стандартне відхилення.\n",
    "Маючи готову функцію генератора, створимо один генератор для наших навчальних даних і по одному для тестових і валідаційних наборів даних.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga4RZN5On5yL"
   },
   "source": [
    "Маючи готову функцію генератора, давайте створимо один генератор для наших навчальних даних і по одному для тестових і валідаційних наборів даних.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtWEAfAnrhMq"
   },
   "outputs": [],
   "source": [
    "print(\"getting test and valid generators...\")\n",
    "\n",
    "# Flow from directory with specified batch size and target image size\n",
    "print(\"raw_train_generator\")\n",
    "raw_train_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory=\"../nih/images_small/\",\n",
    "        x_col=\"Image\", # features\n",
    "        y_col= labels, # labels\n",
    "        class_mode=\"raw\", # 'Mass' column should be in train_df\n",
    "        batch_size= 100, # images per batch\n",
    "        shuffle=True, # shuffle the rows or not\n",
    "        target_size=(320,320) # width and height of output image\n",
    ")\n",
    "\n",
    "# get data sample\n",
    "batch = next(raw_train_generator)\n",
    "data_sample = batch[0]\n",
    "\n",
    "# use sample to fit mean and std for test set generator\n",
    "image_generator = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization= True)\n",
    "\n",
    "# fit generator to sample from training data\n",
    "image_generator.fit(data_sample)\n",
    "\n",
    "# get valid generator\n",
    "print(\"valid_generator\")\n",
    "valid_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory=\"../nih/images_small/\",\n",
    "        x_col=\"Image\", # features\n",
    "        y_col= labels, # labels\n",
    "        class_mode=\"raw\", # 'Mass' column should be in valid_df\n",
    "        batch_size= 8, # images per batch\n",
    "        seed= 1,\n",
    "        shuffle=False, # shuffle the rows or not\n",
    "        target_size=(320,320) # width and height of output image\n",
    ")\n",
    "\n",
    "# get test generator\n",
    "print(\"test_generator\")\n",
    "test_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        directory=\"../nih/images_small/\",\n",
    "        x_col=\"Image\", # features\n",
    "        y_col= labels, # labels\n",
    "        class_mode=\"raw\", # 'Mass' column should be in test_df\n",
    "        batch_size= 8, # images per batch\n",
    "        seed= 1,\n",
    "        shuffle=False, # shuffle the rows or not\n",
    "        target_size=(320,320) # width and height of output image\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYtXacDgn5yN"
   },
   "source": [
    "Давайте подивимось, що генератор дає нашій моделі під час навчання та перевірки. Це можна зробити за допомогою виклику функції __get_item__(index):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jh77vpN-n5yO"
   },
   "outputs": [],
   "source": [
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    generated_image, label = train_generator.__getitem__(i)\n",
    "    plt.imshow(generated_image[i])\n",
    "    plt.colorbar()\n",
    "#plt.title('Raw Chest X Ray Image')\n",
    "#print(f\"The dimensions of the image are {generated_image.shape[1]} pixels width and {generated_image.shape[2]} pixels height\")\n",
    "#print(f\"The maximum pixel value is {generated_image.max():.4f} and the minimum is {generated_image.min():.4f}\")\n",
    "#print(f\"The mean value of the pixels is {generated_image.mean():.4f} and the standard deviation is {generated_image.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WBMpRxcDMgp"
   },
   "source": [
    "<a name='3'></a>\n",
    "**3 Розробка моделі**\n",
    "\n",
    "Тепер ми перейдемо до навчання та розробки моделі. Однак перед тим, як навчати нейронну мережу, нам потрібно вирішити кілька практичних проблем. Перша - це дисбаланс класів.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHBSgvxfn5yR"
   },
   "source": [
    "<a name='3-1'>\n",
    "\n",
    "Вирішення проблеми дисбалансу класів\n",
    "Однією з проблем при роботі з наборами медичних діагностичних даних є значний дисбаланс класів, присутній у таких наборах даних. Давайте побудуємо графік частоти кожної з міток у нашому наборі даних:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OvyPe5en5yR"
   },
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(x=labels, height=np.mean(train_generator.labels, axis=0))\n",
    "plt.title(\"Frequency of Each Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yxHoi8ImbwW6"
   },
   "source": [
    "З цього графіка ми бачимо, що поширеність позитивних випадків суттєво відрізняється для різних патологій. (Ці тенденції також відображають тенденції в повному наборі даних).\n",
    "\n",
    "Патологія грижі має найбільший дисбаланс: частка позитивних випадків лікування становить близько 0,2%.\n",
    "Але навіть патологія Інфільтрація, яка має найменший дисбаланс, має лише 17,5% випадків навчання, позначених як позитивні.\n",
    "В ідеалі, ми б навчали нашу модель, використовуючи рівномірно збалансований набір даних, щоб позитивні і негативні навчальні випадки вносили однаковий внесок у втрати.\n",
    "\n",
    "Якщо ми використовуємо нормальну функцію втрат перехресної ентропії з дуже незбалансованим набором даних, як ми бачимо тут, то алгоритм буде зацікавлений надати пріоритет класу більшості (тобто негативному в нашому випадку), оскільки він вносить більший внесок у втрати.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZVI5VV2bwXA"
   },
   "source": [
    "<a name='Ex-2'></a>\n",
    "**Вправа 2**\n",
    "Обчислення частот класів\n",
    "Заповніть функцію нижче, щоб обчислити ці частоти для кожної мітки в нашому наборі даних.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZ4KMOI9bwXD"
   },
   "source": [
    "<details>    \n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "<ul>\n",
    "    <li> Use numpy.sum(a, axis=), and choose the axis (0 or 1) </li>\n",
    "</ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpDGeY2cChYD"
   },
   "outputs": [],
   "source": [
    "# UNQ_C2 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "\n",
    "def compute_class_freqs(labels):\n",
    "    \"\"\"\n",
    "    Compute positive and negative frequences for each class.\n",
    "\n",
    "    Args:\n",
    "        labels (np.array): matrix of labels, size (num_examples, num_classes)\n",
    "    Returns:\n",
    "        positive_frequencies (np.array): array of positive frequences for each\n",
    "                                         class, size (num_classes)\n",
    "        negative_frequencies (np.array): array of negative frequences for each\n",
    "                                         class, size (num_classes)\n",
    "    \"\"\"\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "    # total number of patients (rows)\n",
    "    N = labels.shape[0]\n",
    "\n",
    "    positive_frequencies = np.sum(labels,0)/N\n",
    "    negative_frequencies = np.ones_like(positive_frequencies) - positive_frequencies\n",
    "    ### END CODE HERE ###\n",
    "    return positive_frequencies, negative_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BqidQvCaD_xi"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "labels_matrix = np.array(\n",
    "    [[1, 0, 0],\n",
    "     [0, 1, 1],\n",
    "     [1, 0, 1],\n",
    "     [1, 1, 1],\n",
    "     [1, 0, 1]]\n",
    ")\n",
    "print(\"labels:\")\n",
    "print(labels_matrix)\n",
    "\n",
    "test_pos_freqs, test_neg_freqs = compute_class_freqs(labels_matrix)\n",
    "\n",
    "print(f\"pos freqs: {test_pos_freqs}\")\n",
    "\n",
    "print(f\"neg freqs: {test_neg_freqs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fW4Gk3RbwXj"
   },
   "source": [
    "Очікувані результати\n",
    "\n",
    "```Python\n",
    "labels:\n",
    "[[1 0 0]\n",
    " [0 1 1]\n",
    " [1 0 1]\n",
    " [1 1 1]\n",
    " [1 0 1]]\n",
    "pos freqs: [0.8 0.4 0.8]\n",
    "neg freqs: [0.2 0.6 0.2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iye-sQoOFG37"
   },
   "source": [
    "Тепер ми обчислимо частоти для наших навчальних даних.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoxM5jQ0E30D"
   },
   "outputs": [],
   "source": [
    "freq_pos, freq_neg = compute_class_freqs(train_generator.labels)\n",
    "freq_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsJIDPTZn5yW"
   },
   "source": [
    "Давайте візуалізуємо ці два співвідношення внесків поруч для кожної з патологій:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqnNCu4In5yW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\n",
    "plt.xticks(rotation=90)\n",
    "f = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zs3_Rgwwn5yZ"
   },
   "outputs": [],
   "source": [
    "pos_weights = freq_neg\n",
    "neg_weights = freq_pos\n",
    "pos_contribution = np.array(freq_pos) * pos_weights\n",
    "neg_contribution = np.array(freq_neg) * neg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygNZmdyun5ya"
   },
   "source": [
    "Давайте перевіримо це, знову зобразивши два внески поруч один з одним на графіку:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPfSFrxjn5yb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\n",
    "data = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v}\n",
    "                        for l,v in enumerate(neg_contribution)], ignore_index=True)\n",
    "plt.xticks(rotation=90)\n",
    "sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlRHZ2iVbwYZ"
   },
   "source": [
    "<a name='Ex-3'></a>\n",
    "Вправа 3\n",
    "Зважені втрати\n",
    "Заповніть функцію *weighted_loss* нижче, щоб повернути функцію втрат, яка обчислює зважені втрати для кожної партії. Пам'ятайте, що для багатокласових втрат ми додаємо середні втрати для кожного окремого класу. Зауважте, що ми також хочемо додати невелике значення, ϵ , до прогнозованих значень перед тим, як брати їхні логарифми. Це робиться для того, щоб уникнути числової помилки, яка може виникнути, якщо прогнозоване значення виявиться нульовим.\n",
    "\n",
    "Примітка\n",
    "Будь ласка, використовуйте функції *Keras* для обчислення середнього значення та логарифму.\n",
    "\n",
    "\n",
    "- [Keras.mean](https://www.tensorflow.org/api_docs/python/tf/keras/backend/mean)\n",
    "- [Keras.log](https://www.tensorflow.org/api_docs/python/tf/keras/backend/log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPIBVAasn5yd"
   },
   "outputs": [],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n",
    "    \"\"\"\n",
    "    Return weighted loss function given negative weights and positive weights.\n",
    "\n",
    "    Args:\n",
    "      pos_weights (np.array): array of positive weights for each class, size (num_classes)\n",
    "      neg_weights (np.array): array of negative weights for each class, size (num_classes)\n",
    "\n",
    "    Returns:\n",
    "      weighted_loss (function): weighted loss function\n",
    "    \"\"\"\n",
    "    def weighted_loss(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Return weighted loss value.\n",
    "\n",
    "        Args:\n",
    "            y_true (Tensor): Tensor of true labels, size is (num_examples, num_classes)\n",
    "            y_pred (Tensor): Tensor of predicted labels, size is (num_examples, num_classes)\n",
    "        Returns:\n",
    "            loss (Tensor): overall scalar loss summed across all classes\n",
    "        \"\"\"\n",
    "        # initialize loss to zero\n",
    "        loss = 0.0\n",
    "\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "        for i in range(len(pos_weights)):\n",
    "            # for each class, add average weighted loss for that class\n",
    "            positive_term_loss = pos_weights[i]*y_true[:,i]*K.log(y_pred[:,i] + epsilon)\n",
    "            negative_term_loss = neg_weights[i]*(1-y_true[:,i])*K.log(1-y_pred[:,i] + epsilon)\n",
    "            loss +=  -K.mean(positive_term_loss + negative_term_loss)  #complete this line\n",
    "        return loss\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuyOnO8EbwYr"
   },
   "source": [
    "Тепер давайте протестуємо нашу функцію на деяких простих прикладах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFjYda3Wulbm"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "sess = K.get_session()\n",
    "with sess.as_default() as sess:\n",
    "    print(\"Test example:\\n\")\n",
    "    y_true = K.constant(np.array(\n",
    "        [[1, 1, 1],\n",
    "         [1, 1, 0],\n",
    "         [0, 1, 0],\n",
    "         [1, 0, 1]]\n",
    "    ))\n",
    "    print(\"y_true:\\n\")\n",
    "    print(y_true.eval())\n",
    "\n",
    "    w_p = np.array([0.25, 0.25, 0.5])\n",
    "    w_n = np.array([0.75, 0.75, 0.5])\n",
    "    print(\"\\nw_p:\\n\")\n",
    "    print(w_p)\n",
    "\n",
    "    print(\"\\nw_n:\\n\")\n",
    "    print(w_n)\n",
    "\n",
    "    y_pred_1 = K.constant(0.7*np.ones(y_true.shape))\n",
    "    print(\"\\ny_pred_1:\\n\")\n",
    "    print(y_pred_1.eval())\n",
    "\n",
    "    y_pred_2 = K.constant(0.3*np.ones(y_true.shape))\n",
    "    print(\"\\ny_pred_2:\\n\")\n",
    "    print(y_pred_2.eval())\n",
    "\n",
    "    # test with a large epsilon in order to catch errors\n",
    "    L = get_weighted_loss(w_p, w_n, epsilon=1)\n",
    "\n",
    "    print(\"\\nIf we weighted them correctly, we expect the two losses to be the same.\")\n",
    "    L1 = L(y_true, y_pred_1).eval()\n",
    "    L2 = L(y_true, y_pred_2).eval()\n",
    "    print(f\"\\nL(y_pred_1)= {L1:.4f}, L(y_pred_2)= {L2:.4f}\")\n",
    "    print(f\"Difference is L1 - L2 = {L1 - L2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDZQMmlgn5yh"
   },
   "source": [
    "<a name='3-3'></a>\n",
    "Далі ми використаємо попередньо навчену модель DenseNet121 (https://www.kaggle.com/pytorch/densenet121), яку ми можемо завантажити безпосередньо з Keras, а потім додати два шари поверх неї:\n",
    "\n",
    "Шар GlobalAveragePooling2D для отримання середнього значення останніх шарів згортки з DenseNet121.\n",
    "Шар Dense з сигмоїдною активацією для отримання логів прогнозу для кожного з наших класів.\n",
    "Ми можемо задати власну функцію втрат для моделі, вказавши параметр loss у функції compile.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZlxoCTgn5yi",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = DenseNet121(weights='../nih/densenet.hdf5', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# and a logistic layer\n",
    "predictions = Dense(len(labels), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "model.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcwhQdOAn5ym"
   },
   "source": [
    "<a name='4'></a>\n",
    "\n",
    "**4 Навчання**\n",
    "\n",
    "Коли наша модель готова до навчання, ми використаємо функцію model.fit() у Keras для навчання нашої моделі.\n",
    "\n",
    "Ми тренуємось на невеликій підмножині набору даних (~1%).\n",
    "Тому на даному етапі нам важливо переконатися, що втрати на навчальній вибірці зменшуються.\n",
    "Оскільки навчання може зайняти значний час, у педагогічних цілях ми вирішили не навчати модель тут, а завантажити набір попередньо навчених ваг у наступному розділі. Однак ви можете використовувати код, показаний нижче, щоб потренувати модель локально на вашому комп'ютері або в Colab.\n",
    "\n",
    "ПРИМІТКА: Не запускайте наведений нижче код на платформі Coursera, оскільки він перевищить обмеження пам'яті платформи.\n",
    "\n",
    "Код на Python для навчання моделі:\n",
    "\n",
    "```python\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=valid_generator,\n",
    "                              steps_per_epoch=100,\n",
    "                              validation_steps=25,\n",
    "                              epochs = 3)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB5nsGKrn5yp"
   },
   "source": [
    "<a name='4-1'></a>\n",
    "Навчання на великому наборі даних\n",
    "Враховуючи, що оригінальний набір даних має розмір 40 ГБ+, а процес навчання на повному наборі даних займає кілька годин, ми навчили модель на машині з графічним процесором і надали вам файл ваг нашої моделі (з розміром партії 32) для використання в подальшому завданні.\n",
    "\n",
    "Архітектура моделі для нашої попередньо навченої моделі точно така ж, але ми використали кілька корисних «зворотних викликів» Keras для цього навчання. Витратьте час, щоб прочитати про ці зворотні виклики на дозвіллі, оскільки вони будуть дуже корисними для управління довготривалими навчальними сесіями:\n",
    "\n",
    "Ви можете використовувати ModelCheckpoint для моніторингу метрики val_loss вашої моделі та збереження знімка вашої моделі в точці.\n",
    "Ви можете використовувати утиліту TensorBoard для моніторингу ваших тренувань в реальному часі за допомогою тензорної дошки Tensorflow.\n",
    "Ви можете використовувати ReduceLROnPlateau для повільного зниження швидкості навчання вашої моделі, коли вона перестає покращуватися за такою метрикою, як val_loss, щоб точно налаштувати модель на останніх етапах навчання.\n",
    "Ви можете використовувати зворотний виклик EarlyStopping, щоб зупинити завдання навчання, коли ваша модель перестане покращуватися за показником втрати валідації. Ви можете встановити значення терпіння - кількість епох, після яких модель не покращується, після чого навчання буде припинено. Цей колбек також може зручно відновити ваги для найкращої метрики в кінці навчання для вашої моделі.\n",
    "Ви можете прочитати про ці та інші корисні зворотні виклики Keras тут (https://keras.io/callbacks/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "887bSajLn5yq"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"../nih/pretrained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA90g8n6suRV"
   },
   "source": [
    "<a name='5'></a>\n",
    "**5 Прогнозування та оцінка**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz1BEwOyxFbj"
   },
   "source": [
    "\n",
    "Тепер, коли у нас є модель, давайте оцінимо її на нашому тестовому наборі. Ми можемо зручно використовувати функцію predict_generator для генерації прогнозів для зображень у нашому тестовому наборі.\n",
    "\n",
    "Примітка: наступна комірка може працювати близько 4 хвилин.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzNrhtf1w2bI",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_vals = model.predict(test_generator, steps = len(test_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtjCtaGen5yt"
   },
   "source": [
    "<a name='5-1'></a>\n",
    "\n",
    "Крива ROC та AUROC\n",
    "Ми розглянемо тему оцінювання моделей набагато детальніше в наступних розділах, а зараз ми розглянемо обчислення метрики, яка називається AUC (площа під кривою) з кривої ROC (робоча характеристика приймача). Цей показник також називають значенням AUROC, але ви побачите, що всі три терміни відносяться до цієї методики і часто використовуються майже як взаємозамінні.\n",
    "\n",
    "Наразі, щоб інтерпретувати графік, вам потрібно знати, що крива, яка знаходиться лівіше і вище, має більшу «площу» під собою, і вказує на те, що модель працює краще.\n",
    "\n",
    "Ми будемо використовувати функцію util.get_roc_curve(), яка була надана вам у файлі util.py. Перегляньте цю функцію і зверніть увагу на використання функцій бібліотеки sklearn для генерації ROC-кривих і значень AUROC для нашої моделі.\n",
    " ([Receiver Operating Characteristic](https://en.wikipedia.org/wiki/Receiver_operating_characteristic))\n",
    "\n",
    "- [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
    "- [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SLI8FHun5yw",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auc_rocs = util.get_roc_curve(labels, predicted_vals, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWZkl01ruZ7P"
   },
   "source": [
    "You can compare the performance to the AUCs reported in the original ChexNeXt paper in the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZUoShw2n5yy"
   },
   "source": [
    "Цей метод також використовує кілька інших прийомів, таких як самонавчання та ансамблі, які можуть дати значний поштовх для покращення виконання:\n",
    "\n",
    "<img src=\"https://journals.plos.org/plosmedicine/article/figure/image?size=large&id=10.1371/journal.pmed.1002686.t001\" width=\"80%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jzy7fLgFn5yy"
   },
   "source": [
    "\n",
    "Для отримання більш детальної інформації про найкращі методи та їхню ефективність на цьому наборі даних, ми рекомендуємо вам ознайомитися з наступними статтями:\n",
    "- [CheXNet](https://arxiv.org/abs/1711.05225)\n",
    "- [CheXpert](https://arxiv.org/pdf/1901.07031.pdf)\n",
    "- [ChexNeXt](https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002686)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gu9ExySryY6u"
   },
   "source": [
    "Однією з проблем використання глибокого навчання в медицині є те, що складна архітектура нейронних мереж робить їх набагато складнішими для інтерпретації порівняно з традиційними моделями машинного навчання (наприклад, лінійними моделями).\n",
    "\n",
    "Одним з найпоширеніших підходів, спрямованих на підвищення інтерпретованості моделей для задач комп'ютерного зору, є використання карт активації класів (Class Activation Maps, CAM).\n",
    "\n",
    "Карти активації класів корисні для розуміння того, куди «дивиться» модель при класифікації зображення.\n",
    "У цьому розділі ми використаємо техніку GradCAM (https://arxiv.org/abs/1610.02391)для створення теплової карти, що виділяє важливі області на зображенні для прогнозування патологічного стану.\n",
    "\n",
    "Це робиться шляхом вилучення градієнтів кожного передбачуваного класу, що перетікають у фінальний згорточний шар нашої моделі. Подивіться на util.compute_gradcam, який ми надали вам у файлі util.py, щоб побачити, як це робиться у фреймворку Keras.\n",
    "Варто зазначити, що GradCAM не надає повного пояснення причин кожної ймовірності класифікації.\n",
    "\n",
    "Однак, це все ще корисний інструмент для «налагодження» нашої моделі та покращення прогнозу, щоб експерт міг підтвердити, що прогноз дійсно обумовлений тим, що модель фокусується на правильних ділянках зображення.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeRz7v88bwZp"
   },
   "source": [
    "Спочатку ми завантажимо невелику навчальну вибірку і налаштуємо її на перегляд 4 класів з найвищими показниками AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6kahoZbJn5yz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../nih/train-small.csv\")\n",
    "IMAGE_DIR = \"../nih/images_small/\"\n",
    "\n",
    "# only show the lables with top 4 AUC\n",
    "labels_to_show = np.take(labels, np.argsort(auc_rocs)[::-1])[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmtfk2oQbwZ0"
   },
   "source": [
    "Тепер давайте подивимося на кілька конкретних зображень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIbXB584bwZ2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "util.compute_gradcam(model, '00008270_015.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JC2zy1Kpn5y1"
   },
   "outputs": [],
   "source": [
    "util.compute_gradcam(model, '00011355_002.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCHVaLMQn5y2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "util.compute_gradcam(model, '00029855_001.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGwL8FcFn5y4"
   },
   "outputs": [],
   "source": [
    "util.compute_gradcam(model, '00005410_000.png', IMAGE_DIR, df, labels, labels_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8KB7SmVbwah"
   },
   "source": [
    "Вітаємо, ви виконали перше завдання першого курсу! Ви навчилися попередньо обробляти дані, перевіряти їх на витік, навчати попередньо навчену модель та оцінювати за допомогою AUC. Чудова робота!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHjnSOW0k85s"
   },
   "source": [
    "Отримання прогнозів моделі на випадково вибраних зображеннях з тестового набору даних\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMx9E7wwk85s"
   },
   "outputs": [],
   "source": [
    "# Visualize images for true class \"Atelectasis\"\n",
    "class_label = 'Atelectasis'\n",
    "test_class = test_df.loc[test_df[class_label]==1,:]\n",
    "\n",
    "# Define number of images to plot\n",
    "number_of_images = 9\n",
    "custom_df = test_class.sample(n=number_of_images)\n",
    "\n",
    "# Get predicted labels\n",
    "labels = custom_df.columns.tolist()[2:]\n",
    "true_classes = custom_df.iloc[:,2:].values==1\n",
    "selected_predictions = predicted_vals[custom_df.index,:]>0.5\n",
    "\n",
    "true_labels, pred_labels = [], []\n",
    "for i in np.arange(0, selected_predictions.shape[0]):\n",
    "    true_labels.append(list(compress(labels, true_classes[i,:])))\n",
    "    pred_labels.append(list(compress(labels, selected_predictions[i,:])))\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=1.5,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.title('True class: ' + '\\n' +  ', '.join(true_labels[i]) + \\\n",
    "              '\\n' 'Predicted class: ' + '\\n' + ', '.join(pred_labels[i]) + '\\n', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ad7-zYYk85s"
   },
   "outputs": [],
   "source": [
    "# Visualize images for true class \"Emphysema\"\n",
    "class_label = 'Emphysema'\n",
    "test_class = test_df.loc[test_df[class_label]==1,:]\n",
    "\n",
    "# Define number of images to plot\n",
    "number_of_images = 9\n",
    "custom_df = test_class.sample(n=number_of_images)\n",
    "\n",
    "# Get predicted labels\n",
    "labels = custom_df.columns.tolist()[2:]\n",
    "true_classes = custom_df.iloc[:,2:].values==1\n",
    "selected_predictions = predicted_vals[custom_df.index,:]>0.5\n",
    "\n",
    "true_labels, pred_labels = [], []\n",
    "for i in np.arange(0, selected_predictions.shape[0]):\n",
    "    true_labels.append(list(compress(labels, true_classes[i,:])))\n",
    "    pred_labels.append(list(compress(labels, selected_predictions[i,:])))\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=1.5,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.title('True class: ' + '\\n' +  ', '.join(true_labels[i]) + \\\n",
    "              '\\n' 'Predicted class: ' + '\\n' + ', '.join(pred_labels[i]) + '\\n', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmQ0gCAPk85t"
   },
   "outputs": [],
   "source": [
    "# Visualize images for true class \"Infiltration\"\n",
    "class_label = 'Infiltration'\n",
    "test_class = test_df.loc[test_df[class_label]==1,:]\n",
    "\n",
    "# Define number of images to plot\n",
    "number_of_images = 9\n",
    "custom_df = test_class.sample(n=number_of_images)\n",
    "\n",
    "# Get predicted labels\n",
    "labels = custom_df.columns.tolist()[2:]\n",
    "true_classes = custom_df.iloc[:,2:].values==1\n",
    "selected_predictions = predicted_vals[custom_df.index,:]>0.5\n",
    "\n",
    "true_labels, pred_labels = [], []\n",
    "for i in np.arange(0, selected_predictions.shape[0]):\n",
    "    true_labels.append(list(compress(labels, true_classes[i,:])))\n",
    "    pred_labels.append(list(compress(labels, selected_predictions[i,:])))\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=1.5,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.title('True class: ' + '\\n' +  ', '.join(true_labels[i]) + \\\n",
    "              '\\n' 'Predicted class: ' + '\\n' + ', '.join(pred_labels[i]) + '\\n', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z91G5-4kk85t"
   },
   "outputs": [],
   "source": [
    "# Visualize images for true class \"Mass\"\n",
    "class_label = 'Mass'\n",
    "test_class = test_df.loc[test_df[class_label]==1,:]\n",
    "\n",
    "# Define number of images to plot\n",
    "number_of_images = 9\n",
    "custom_df = test_class.sample(n=number_of_images)\n",
    "\n",
    "# Get predicted labels\n",
    "labels = custom_df.columns.tolist()[2:]\n",
    "true_classes = custom_df.iloc[:,2:].values==1\n",
    "selected_predictions = predicted_vals[custom_df.index,:]>0.5\n",
    "\n",
    "true_labels, pred_labels = [], []\n",
    "for i in np.arange(0, selected_predictions.shape[0]):\n",
    "    true_labels.append(list(compress(labels, true_classes[i,:])))\n",
    "    pred_labels.append(list(compress(labels, selected_predictions[i,:])))\n",
    "\n",
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1,\n",
    "                    right=0.9,\n",
    "                    top=1.5,\n",
    "                    wspace=0.4,\n",
    "                    hspace=0.4)\n",
    "\n",
    "for i, image_name in enumerate(custom_df['Image'].values):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    image = plt.imread(os.path.join(\"../nih/images_small/\", image_name))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.title('True class: ' + '\\n' +  ', '.join(true_labels[i]) + \\\n",
    "              '\\n' 'Predicted class: ' + '\\n' + ', '.join(pred_labels[i]) + '\\n', fontsize=16)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "coursera": {
   "schema_names": [
    "AI4MC1-1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
